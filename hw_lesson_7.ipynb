{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW7 Мельчук А.Б."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Запустить seq2seq, seq2seq с внимаием и трансформер для перевода русских слов + описать наблюдения по качеству\n",
    "    Данные в папке data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 60\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 1.1304 - accuracy: 0.7745 - val_loss: 0.9147 - val_accuracy: 0.7586\n",
      "Epoch 2/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.7338 - accuracy: 0.8031 - val_loss: 0.7792 - val_accuracy: 0.7959\n",
      "Epoch 3/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.6327 - accuracy: 0.8325 - val_loss: 0.6907 - val_accuracy: 0.8117\n",
      "Epoch 4/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.6255 - accuracy: 0.8362 - val_loss: 0.6558 - val_accuracy: 0.8183\n",
      "Epoch 5/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.5447 - accuracy: 0.8478 - val_loss: 0.6145 - val_accuracy: 0.8255\n",
      "Epoch 6/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.5154 - accuracy: 0.8540 - val_loss: 0.5891 - val_accuracy: 0.8328\n",
      "Epoch 7/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4951 - accuracy: 0.8587 - val_loss: 0.5702 - val_accuracy: 0.8363\n",
      "Epoch 8/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4788 - accuracy: 0.8621 - val_loss: 0.5565 - val_accuracy: 0.8382\n",
      "Epoch 9/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4633 - accuracy: 0.8653 - val_loss: 0.5419 - val_accuracy: 0.8432\n",
      "Epoch 10/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4506 - accuracy: 0.8684 - val_loss: 0.5298 - val_accuracy: 0.8443\n",
      "Epoch 11/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4390 - accuracy: 0.8715 - val_loss: 0.5155 - val_accuracy: 0.8495\n",
      "Epoch 12/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4274 - accuracy: 0.8747 - val_loss: 0.5095 - val_accuracy: 0.8524\n",
      "Epoch 13/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4169 - accuracy: 0.8779 - val_loss: 0.5036 - val_accuracy: 0.8535\n",
      "Epoch 14/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4072 - accuracy: 0.8809 - val_loss: 0.4943 - val_accuracy: 0.8570\n",
      "Epoch 15/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3975 - accuracy: 0.8836 - val_loss: 0.4854 - val_accuracy: 0.8592\n",
      "Epoch 16/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3887 - accuracy: 0.8862 - val_loss: 0.4826 - val_accuracy: 0.8604\n",
      "Epoch 17/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3800 - accuracy: 0.8890 - val_loss: 0.4750 - val_accuracy: 0.8637\n",
      "Epoch 18/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3714 - accuracy: 0.8912 - val_loss: 0.4701 - val_accuracy: 0.8646\n",
      "Epoch 19/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3628 - accuracy: 0.8938 - val_loss: 0.4666 - val_accuracy: 0.8654\n",
      "Epoch 20/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3550 - accuracy: 0.8964 - val_loss: 0.4612 - val_accuracy: 0.8678\n",
      "Epoch 21/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3462 - accuracy: 0.8991 - val_loss: 0.4540 - val_accuracy: 0.8709\n",
      "Epoch 22/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3388 - accuracy: 0.9013 - val_loss: 0.4486 - val_accuracy: 0.8724\n",
      "Epoch 23/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3305 - accuracy: 0.9037 - val_loss: 0.4469 - val_accuracy: 0.8729\n",
      "Epoch 24/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3226 - accuracy: 0.9058 - val_loss: 0.4447 - val_accuracy: 0.8742\n",
      "Epoch 25/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3155 - accuracy: 0.9077 - val_loss: 0.4370 - val_accuracy: 0.8765\n",
      "Epoch 26/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3076 - accuracy: 0.9104 - val_loss: 0.4369 - val_accuracy: 0.8762\n",
      "Epoch 27/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.3084 - accuracy: 0.9101 - val_loss: 0.4462 - val_accuracy: 0.8731\n",
      "Epoch 28/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3022 - accuracy: 0.9115 - val_loss: 0.4297 - val_accuracy: 0.8780\n",
      "Epoch 29/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2894 - accuracy: 0.9155 - val_loss: 0.4279 - val_accuracy: 0.8789\n",
      "Epoch 30/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2821 - accuracy: 0.9173 - val_loss: 0.4274 - val_accuracy: 0.8792\n",
      "Epoch 31/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2757 - accuracy: 0.9192 - val_loss: 0.4274 - val_accuracy: 0.8785\n",
      "Epoch 32/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2688 - accuracy: 0.9211 - val_loss: 0.4275 - val_accuracy: 0.8803\n",
      "Epoch 33/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2628 - accuracy: 0.9224 - val_loss: 0.4252 - val_accuracy: 0.8799\n",
      "Epoch 34/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2570 - accuracy: 0.9243 - val_loss: 0.4232 - val_accuracy: 0.8812\n",
      "Epoch 35/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2502 - accuracy: 0.9264 - val_loss: 0.4248 - val_accuracy: 0.8815\n",
      "Epoch 36/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2439 - accuracy: 0.9281 - val_loss: 0.4230 - val_accuracy: 0.8822\n",
      "Epoch 37/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2381 - accuracy: 0.9299 - val_loss: 0.4267 - val_accuracy: 0.8819\n",
      "Epoch 38/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2336 - accuracy: 0.9310 - val_loss: 0.4237 - val_accuracy: 0.8818\n",
      "Epoch 39/60\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.2266 - accuracy: 0.9328 - val_loss: 0.4276 - val_accuracy: 0.8814\n",
      "Epoch 40/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2206 - accuracy: 0.9344 - val_loss: 0.4249 - val_accuracy: 0.8838\n",
      "Epoch 41/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2153 - accuracy: 0.9362 - val_loss: 0.4282 - val_accuracy: 0.8830\n",
      "Epoch 42/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2103 - accuracy: 0.9373 - val_loss: 0.4333 - val_accuracy: 0.8820\n",
      "Epoch 43/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.2050 - accuracy: 0.9391 - val_loss: 0.4320 - val_accuracy: 0.8834\n",
      "Epoch 44/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1992 - accuracy: 0.9406 - val_loss: 0.4376 - val_accuracy: 0.8833\n",
      "Epoch 45/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1943 - accuracy: 0.9421 - val_loss: 0.4405 - val_accuracy: 0.8825\n",
      "Epoch 46/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1899 - accuracy: 0.9433 - val_loss: 0.4412 - val_accuracy: 0.8837\n",
      "Epoch 47/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1845 - accuracy: 0.9450 - val_loss: 0.4405 - val_accuracy: 0.8837\n",
      "Epoch 48/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1797 - accuracy: 0.9461 - val_loss: 0.4460 - val_accuracy: 0.8829\n",
      "Epoch 49/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1742 - accuracy: 0.9479 - val_loss: 0.4460 - val_accuracy: 0.8834\n",
      "Epoch 50/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1703 - accuracy: 0.9488 - val_loss: 0.4525 - val_accuracy: 0.8831\n",
      "Epoch 51/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1658 - accuracy: 0.9502 - val_loss: 0.4517 - val_accuracy: 0.8838\n",
      "Epoch 52/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1604 - accuracy: 0.9518 - val_loss: 0.4536 - val_accuracy: 0.8839\n",
      "Epoch 53/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1564 - accuracy: 0.9530 - val_loss: 0.4591 - val_accuracy: 0.8843\n",
      "Epoch 54/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1518 - accuracy: 0.9540 - val_loss: 0.4630 - val_accuracy: 0.8831\n",
      "Epoch 55/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1481 - accuracy: 0.9551 - val_loss: 0.4697 - val_accuracy: 0.8827\n",
      "Epoch 56/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1439 - accuracy: 0.9567 - val_loss: 0.4742 - val_accuracy: 0.8831\n",
      "Epoch 57/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1404 - accuracy: 0.9573 - val_loss: 0.4750 - val_accuracy: 0.8835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1362 - accuracy: 0.9587 - val_loss: 0.4764 - val_accuracy: 0.8841\n",
      "Epoch 59/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1323 - accuracy: 0.9600 - val_loss: 0.4808 - val_accuracy: 0.8841\n",
      "Epoch 60/60\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1276 - accuracy: 0.9613 - val_loss: 0.4863 - val_accuracy: 0.8834\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Ночально?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Круто!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Круто!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Круто!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Круто!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Круто!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Круто!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгайте!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгайте!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгайте!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгайте!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence: Сделай это.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Продолжай.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Продолжай.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Сапреши!\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежал.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежал.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежал.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежал.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я вижу на говор.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я вижу на говор.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я вижу на говор.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я повыл.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я повыл.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я повыл.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграл!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграл!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграл!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграл!\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Она слабаю!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьте.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьте.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьте.\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Покалите!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: В атаку!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Съешь это.\n",
      "\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Поешай.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Ни скужайте!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Ни скужайте!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Ни скужайте!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Ни скужайте!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Поднимайтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Поднимайтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Поднимайтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Понял!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение количества эпох до 60ти сильно повысило качество перевода. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "data_path = 'data/rus-eng/rus.txt'\n",
    "num_samples = 10000\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.1044\n",
      "Epoch 2 Loss 0.0296\n",
      "Epoch 3 Loss 0.0241\n",
      "Epoch 4 Loss 0.0204\n",
      "Epoch 5 Loss 0.0189\n",
      "Epoch 6 Loss 0.0173\n",
      "Epoch 7 Loss 0.0159\n",
      "Epoch 8 Loss 0.0254\n",
      "Epoch 9 Loss 0.0179\n",
      "Epoch 10 Loss 0.0150\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Input: <start> good morning <end>\n",
      "Predicted translation: ! <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/anaconda3/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['char', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c62fe7b3b252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pylab'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'good morning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-61331b77bd12>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted translation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-61331b77bd12>\u001b[0m in \u001b[0;36mplot_attention\u001b[0;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAH1CAYAAACQrwgRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa80lEQVR4nO3de7jtBV3n8c8XDqKASqGiNipe81Z5odQcnbxMlpVjk928ZGpSVtrNarQpzaaLDdbQZSY1NZVycioHm3oytSYd8hKaiegjUioZGWCWcFRE+M4fa23cbg5wDuj5rf09r9fz7Id1fr+19/4ennX2eu/ftbo7AADsboctPQAAANedqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAfB5U1WXV9VlV/Gxt6r+pqqetvScMMGepQcAYLTvT/LsJK9K8pb1svskeWSS5ya5VZJfqKru7l9dZEIYorp76RnYIFV1xyTPT/ID3X3m0vMAu1tVnZbk1d39oh3Ln5TkEd39H6rqe5I8tbvvtsiQMITdr+z0+CRfleSJC88BzPCQJH+xj+V/keSh68evTXLbgzYRDCXquEJVVZLHJXlxkkdX1eELjwTsfh/JalfrTo9McuH68TFJ/vWgTQRDOaaO7R6U5IZJnpbka5M8PMkfLjoRsNv9dJIXVtWDk7w1SSf5iiRfneTJ6+f8++x7ax5wABxTxxWq6reSfKq7T6qqk5Oc0N2PWngsYJerqvsleWqSOyepJO9J8ivd/eZFB4NhRB1Jkqo6Osk/Jvm67n5jVd0jyZuS3LK7P7rsdADANbH7lS3flOTC7n5jknT3O6rqfUm+Lcn/WHQyYNerqlsmuVl2HMvd3W9fZiI22XpDwzclOa27HW+5n5wowZbHJTl1x7JTszobFuBaqap7VtVZSf4+yduTnLHt46+WnI2N9i1JXpLVexP7ye5XUlW3SvL+JHfp7vdtW/5vknwgyV27++yFxgN2sar6q6zOgH1OkvOyOlHiCt39wSXmYrNV1f/Nasvux7v7xIXH2TVEHQCfN1W1N8k9/WLI/qqqE5KcndVZ0m9Ocq/ufveSM+0Wdr+SJKmqW6+vU7fPdQd7HmCMM5PcfOkh2FUel+SN3f2OJH8chwHtN1HHlvcnuenOhVV13HodwLXxzCS/WFUPrarjq+oLt38sPRwb6TuSvHz9+NQkj7mqjQ58NrtfSZJU1eVJju/uC3Ysv02Sd3f30ctMBuxm658tW7a/4VSS7m53ruEKVfWVSf40q/ejvVV1vSQfTvKt3f3aZafbfC5pcoirql9ZP+wkP19VH9+2+vCsjml4x0EfDJjiQUsPwK7y+KwuY7I3Sbr7U1X1yiTfmdU9grkaoo4vWf+3ktwlyae2rftUVpcgOPlgDwXM0N1u/8V+qaojs7qUybfvWHVqktdU1THdffHBn2z3sPuVrI9VeGWSJ3b3RUvPA+xuVXWvJO/o7svXj6+Siw+zpapuktU9x1/eO+Kkqh6b5HXd/eFFhtslRB2pqsOTfDLJlzltHLiu1sfR3by7z18/7qz2BuzkmDr4HLL7lXT3ZVX1wSTXW3oWYITbJrlg22PgILCljiRJVT0+q+MYHtvdFy49DwCHhqp6f3bcaeSqdPftPs/j7Gq21LHl6Vn9Rv0PVfWhJHu3r+zuL11kKmDXq6qjktwjq9s+fdb1Ubv7DxYZik3ya9seH5Pkh5O8Ncmb1svul9WVGJ53kOfadUQdW35v6QHYXFX1U/v73O5+zudzFnaXqnpoklckOW4fqzurSydxCOvuK2Ktqn4ryXO7++e2P6eqnpHkbgd5tF3H7lfgGlXVmTsW3SbJUVndoD1Jbpnk40k+YKsu21XVWUn+Kskzu/u8a3o+h7aq+lhW93o9Z8fyOyR5e3ffaJnJdgdb6oBr1N1b1zNMVT0hq9v4PL67z10vu3WSlyT57WUmZIOdkOQRgo79tDfJVyU5Z8fyr8rqF0euhqgjSbK+FctPZHWyxK2THLF9vcsOsM1PJXnkVtAlSXefW1U/kuS0JC9ebDI20elJvjjJ3y49CLvCLyf59ao6Mcmb18vum9WdJp691FC7hahjy88k+dYkP5/VP6ofzeo37G9L8pPLjcUGOj7JDfax/PpJbnKQZ2Hz/UaSk6vqlknOTHLp9pUuPsx23f2LVfWBJD+Q1d0lkuQ9We0ZeOVig+0SjqkjyRWnlD+lu/+kqi5Kco/u/tuqekqSh3T3oxYekQ1RVacluV2SJ2d1rFSSfHmS5yd5f3c/cqnZ2Dzriw9fFRcfhs8hW+rYcnySrbtJXJzk2PXjP0ny3EUmYlN9V5KXJvnLJJetlx2W5DVZhR5s5+LDXCtVdWyufAmcf15onF1B1LHl3KzOYDw3qwNUH5bkbVldH+gTC87FhunuC5I8vKrulOTOWd3+6T3dffayk7FpquqIJG/Jamv/WUvPw+arqttktcv+QfnsY7srLoFzjUQdW16V5CFZHZh6SpJXVNWTk3xRkv+65GBspu4+u6rOWz3svdf4CRxyuvvSqro0+3m3AMjqLPpjkzwxq0smee0cAMfUsU9VdZ8k909ydnf/n6XnYbNU1fcl+fGsoj9JPpTVBUP/+3JTsYmq6seSfEmSJ3T3p5eeh81WVRcnuW93v2vpWXYjW+pIklTVA5P85dYP3e5+S5K3VNWeqnpgd79h2QnZFFX1zCTPSHJykv+3XvyAJL9QVTfq7l9YbDg20QOS/LusbkH4rlz5FoSPWGQqNtX7kxy59BC7lS11JEmq6rIkt+ju83csPy7J+c5QY0tVnZvkx7v7FTuWPybJz3X3bZaZjE1UVS+5uvXd/YSDNQubr6oenOQ/JfnenXeV4JqJOpJccdmB49cHwW9ffqckZ7g1C1uq6pNJ7r6P2/jcMcmZ3X39ZSYDdrv1JbWOzOqEiEuSfNYue+9FV8/u10NcVb16/bCTnFpVl2xbfXiSu2d16QrYcnaSRyd5zo7lj07y3oM/DrtBVd0uyV2z+lnznu7+u4VHYjN9/9ID7Gaijo+s/1tJPprPvnzJp7I6ZuqFB3soNtqzk7xyfRzm6Vm9Sf/brI6b+uYF52IDVdWNkrwoyTclufwzi+v3kzypuy9abDg2Tne/dOkZdjO7X0mSVNWzkpzs0hTsj6q6d5IfSnKXrH4heHeS53X3Xy86GBtnfUzdVyY5KZ/Z6n//rK5Fdnp3P2mp2dhMVXV8kscluX2Sn+zuC6vq/knO6+73LzvdZhN1JEmq6rAk6e7L13++eZKvT/Lu7rb7FbhWquojSR7Z3W/csfyBSV7V3cctMxmbaP0L4+uzOgv2bknu3N1/V1XPTnKn7n70kvNtOrtf2fJHWd0S7JSqOibJGUmOTnJMVT2pu1+26HRslKo6Mslj8pljpM5K8oruvuRqP5FD0Q3ymcM8tvvnJE6qYaeTk5zS3c9anzSx5TVJnCl9DQ675qdwiLh3kj9bP/6PST6W5GZZ3cvz6UsNxeapqrsmeV+SX0pynyT3TfLfkpxdVXdZcjY20ulJfqaqjtpaUFVHJ/npOAmLK7t3VveW3ukfs7pHOVfDljq23DDJv6wff3VWu0Uurao/S/Lry43FBjolyV8neVx3fyy54mD4U7OKu4ctOBub54ey2gvwD1X1zqy27H5Zko9n9bMGtvtEki/Yx/I7Jzl/H8vZxpY6tpyb5P7r36AfluS16+VfmNUPX9hy/yTP3Aq6JFk//omszoKFK6xv93THJD+a1WEdb18/vkN3n7XkbGyk05I8a32IR5J0VZ2Q5LlJfn+poXYLUceWX0ry8qzu4fkPSbZuC/bAJGcuNRQb6ZNZ3XB7pxuv18FON87qGLr3JTknyfWSPKGqvnfRqdhET89qY8IFSY7K6rJa5yT51yT/ecG5dgVnv3KF9VlHt07y2u6+eL3s65L8S3efvuhwbIyqemmSL8/qeMs3rxffL8nzk7zVbZ/Yrqoem+Q385lrYW5/0+nuvuUig7HR1rcLu1dWG5/e3t2vW3ikXUHUkaq6cZIv3XnJgfW6+2d1WZOPHvzJ2ERVdWxWBzJ/Q5LL1osPz2q3yRO6+1+u6nM59FTVB7N6vTynuz99Tc/n0OW96LoTdaSqbpjVmUUP275FrqrukeQtSb6ouy9caj42U1XdIdsuPuzm2+xLVX00yb3dFoxr4r3ouhN1JEmq6reTXNzd371t2clZXezxEctNxqapqhdfxarO6pi6c5L8bnefd/CmYlNV1a8leW93/+rSs7D5vBddN6KOJElVPSzJK5Icv76UyWFZnTTx/d39B8tOxyapqj9M8oCs7uP5rvXiu2e1xe5tWV0F/pgkD+judywyJBujqq6X5H9ndS/pM5Ncun19dz9nibnYTN6LrhvXqWPLa7O6dMk3JPmDJA/J6gy1P1xyKDbS6Ukuzupm7B9PkvWFZV+Y5G+SPDzJy5I8L6vXEYe2707yNUkuTHKH7DhRIomoYzvvRdeBLXVcoaqem+SLu/uRVfWyJBd19/ctPRebpar+McmDu/s9O5bfNcnru/sWVXXPJK9zX0+q6vwkP9/dv7z0LOwO3ouuPVvq2O5lSd5WVbdK8o2xlYV9OybJLZK8Z8fym6/XJavbzPn5QrI6M/rVSw/BruK96Fpy8WGusL66+5lJfifJh7r7rQuPxGZ6VZIXVdU3V9UJVXWbqvrmJC/KandJknxFkrMXm5BN8pIkj1l6CHYP70XXnt+k2enlWd2/8yeWHoSN9T1Z3YHk1HzmZ8ink7w4q6vBJ6uteE8++KOxgY5K8l3rA+DfmSufKPG0RaZi03kvuhYcU8dnqaovTPLUJM/v7g8vPQ+ba32f4NtnddbrOd29d+GR2EBV9edXs7q7+8EHbRh2De9F146oAwAYwDF1AAADiDoAgAFEHftUVSctPQO7g9cKB8Lrhf3ltXLgRB1XxT8m9pfXCgfC64X95bVygEQdAMAAh/zZr0cceXQfedQXLD3Gxvn0JXuz58ijlx5jo9RlS0+wmS69dG+OOMJrZafDPvGppUfYSJ+6/BO53mE3WHqMjXLHu35s6RE20gUfuSw3Pe7wpcfYOG975yUXdvdN97XukL/48JFHfUHu8aAfWHoMdoEjPqbq2H9HnvX3S4/ALvHHr/nTpUdgFzn8Fud88KrW2f0KADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBggLFRV1UfqKqnLz0HAMDBMDbqAAAOJaIOAGAAUQcAMMDkqLt8/XElVXVSVZ1RVWd8+pK9B3ksAIDPvclRd/H640q6+wXdfWJ3n7jnyKMP8lgAAJ97k6PuX3MVUQcAMM2epQf4fOnuByw9AwDAwTJ2S11Vvb6qnrD0HAAAB8PYqEty+yTHLT0EAMDBMHn36wlLzwAAcLBM3lIHAHDIEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYABRBwAwgKgDABhA1AEADCDqAAAGEHUAAAOIOgCAAUQdAMAAog4AYIA9Sw+wtMv3VD5+k8OXHoNdYM8xfgdi/116wxOWHoFd4iue8ZSlR2BX+ZGrXONdCgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBggF0TdVX19Kr6wNJzAABsol0TdQAAXLXPSdRV1Y2q6tjPxdc6gO9506q6/sH8ngAAm+paR11VHV5VD6uq30ny4SRftl5+46p6QVWdX1UXVdVfVNWJ2z7vO6vq4qp6SFW9q6r2VtWfV9Vtd3z9H6uqD6+f+7Ikx+wY4eFJPrz+Xve/tn8PAIAJDjjqqupuVfWLSc5N8rtJ9ib5miRvqKpK8kdJvijJ1ye5Z5I3JPmzqrrFti9zZJJnJHlikvslOTbJb2z7Ht+S5L8keVaSeyV5b5If3jHKqUkeneSGSV5bVedU1U/tjEMAgEPBfkVdVR1XVU+rqjOS/HWSOyf5wSTHd/eTu/sN3d1JHpTkHkke1d1v7e5zuvsnk/xdksdt+5J7knzf+jnvTHJykgdV1dY8P5jkpd39/O4+u7t/Nslbt8/U3Zd19x9397cnOT7Jz62///vWWwefWFU7t+5t/X1OqqozquqMT39y7/78LwAA2Gj7u6XuqUlOSXJJkjt29yO6+3919yU7nnfvJEcluWC92/Tiqro4yd2T3H7b8y7p7vdu+/N5SY7IaotdktwlyZt2fO2df75Cd1/U3S/u7gcl+fIkN0vyoiSPuornv6C7T+zuE/dc/+ir+WsDAOwOe/bzeS9IcmmS70hyVlW9KsnLk7y+uy/b9rzDkvxTkgfs42t8bNvjT+9Y19s+/4BV1ZFJvi6rrYEPT3JWVlv7Trs2Xw8AYLfZr4jq7vO6+2e7+4uTPDTJxUn+Z5IPVdXzquqe66e+PatdoZevd71u/zj/AOZ6T5L77lj2WX+ulX9bVc/P6kSNX0tyTpJ7d/e9uvuU7v7oAXxPAIBd64C3jHX3m7v7KUlukdVu2TsleWtVPSDJ65KcnuS0qvraqrptVd2vqn56vX5/nZLk8VX15Kq6Y1U9I8l9djznsUn+NMmNknx7klt1949297sO9O8EALDb7e/u1ytZH0/3e0l+r6puluSy7u6qenhWZ66+MKtj2/4pq9B72QF87d+tqtsl+dmsjtF7dZJfSvKd2572+iQ37+6PXfkrAAAcWmp10uqh66ib3qrv/I0/tPQY7AJ7Pnlo/1vhwFzvosuXHoFd4pPHHr70COwib/utH3lbd5+4r3VuEwYAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAFEHQDAAKIOAGAAUQcAMICoAwAYQNQBAAwg6gAABhB1AAADiDoAgAH2LD3A0vZcuDfH/eablh4DgEPUDZYegDFsqQMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwAB7lh5gCVV1UpKTkuT6OWrhaQAArrtDcktdd7+gu0/s7hOPyJFLjwMAcJ0dklEHADCNqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMIOoAAAYQdQAAA4g6AIABRB0AwACiDgBgAFEHADCAqAMAGEDUAQAMUN299AyLqqoLknxw6Tk20E2SXLj0EOwKXiscCK8X9pfXyr7dprtvuq8Vh3zUsW9VdUZ3n7j0HGw+rxUOhNcL+8tr5cDZ/QoAMICoAwAYQNRxVV6w9ADsGl4rHAivF/aX18oBckwdAMAAttQBAAwg6gAABhB1AAADiDoAgAFEHQDAAP8fVwzZ4dBj/YIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "translate(u'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hello\n",
      "Predicted translation: ['<start>', '!']\n"
     ]
    }
   ],
   "source": [
    "translate(u'hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.2216 Accuracy 0.0117\n",
      "Epoch 1 Batch 50 Loss 2.4525 Accuracy 0.1241\n",
      "Epoch 1 Batch 100 Loss 1.7703 Accuracy 0.1908\n",
      "Epoch 1 Loss 1.5871 Accuracy 0.2230\n",
      "Epoch 2 Batch 0 Loss 0.5561 Accuracy 0.4219\n",
      "Epoch 2 Batch 50 Loss 0.3254 Accuracy 0.4613\n",
      "Epoch 2 Batch 100 Loss 0.2397 Accuracy 0.4738\n",
      "Epoch 2 Loss 0.2204 Accuracy 0.4769\n",
      "Epoch 3 Batch 0 Loss 0.1155 Accuracy 0.4961\n",
      "Epoch 3 Batch 50 Loss 0.1179 Accuracy 0.4923\n",
      "Epoch 3 Batch 100 Loss 0.1173 Accuracy 0.4922\n",
      "Epoch 3 Loss 0.1172 Accuracy 0.4920\n",
      "Epoch 4 Batch 0 Loss 0.2580 Accuracy 0.4883\n",
      "Epoch 4 Batch 50 Loss 0.1101 Accuracy 0.4928\n",
      "Epoch 4 Batch 100 Loss 0.1043 Accuracy 0.4921\n",
      "Epoch 4 Loss 0.1024 Accuracy 0.4922\n",
      "Epoch 5 Batch 0 Loss 0.0959 Accuracy 0.4922\n",
      "Epoch 5 Batch 50 Loss 0.0856 Accuracy 0.4933\n",
      "Epoch 5 Batch 100 Loss 0.0847 Accuracy 0.4927\n",
      "Epoch 5 Loss 0.0853 Accuracy 0.4925\n",
      "Epoch 6 Batch 0 Loss 0.0864 Accuracy 0.4961\n",
      "Epoch 6 Batch 50 Loss 0.0724 Accuracy 0.4944\n",
      "Epoch 6 Batch 100 Loss 0.0773 Accuracy 0.4940\n",
      "Epoch 6 Loss 0.0767 Accuracy 0.4938\n",
      "Epoch 7 Batch 0 Loss 0.0705 Accuracy 0.4922\n",
      "Epoch 7 Batch 50 Loss 0.0627 Accuracy 0.4951\n",
      "Epoch 7 Batch 100 Loss 0.0681 Accuracy 0.4944\n",
      "Epoch 7 Loss 0.0678 Accuracy 0.4950\n",
      "Epoch 8 Batch 0 Loss 0.0308 Accuracy 0.5000\n",
      "Epoch 8 Batch 50 Loss 0.0718 Accuracy 0.4948\n",
      "Epoch 8 Batch 100 Loss 0.0669 Accuracy 0.4950\n",
      "Epoch 8 Loss 0.0671 Accuracy 0.4950\n",
      "Epoch 9 Batch 0 Loss 0.0388 Accuracy 0.4961\n",
      "Epoch 9 Batch 50 Loss 0.0573 Accuracy 0.4959\n",
      "Epoch 9 Batch 100 Loss 0.0610 Accuracy 0.4952\n",
      "Epoch 9 Loss 0.0617 Accuracy 0.4954\n",
      "Epoch 10 Batch 0 Loss 0.0164 Accuracy 0.4961\n",
      "Epoch 10 Batch 50 Loss 0.0588 Accuracy 0.4964\n",
      "Epoch 10 Batch 100 Loss 0.0585 Accuracy 0.4957\n",
      "Epoch 10 Loss 0.0587 Accuracy 0.4958\n",
      "Epoch 11 Batch 0 Loss 0.1263 Accuracy 0.4961\n",
      "Epoch 11 Batch 50 Loss 0.0536 Accuracy 0.4972\n",
      "Epoch 11 Batch 100 Loss 0.0558 Accuracy 0.4959\n",
      "Epoch 11 Loss 0.0549 Accuracy 0.4960\n",
      "Epoch 12 Batch 0 Loss 0.0973 Accuracy 0.4922\n",
      "Epoch 12 Batch 50 Loss 0.0552 Accuracy 0.4966\n",
      "Epoch 12 Batch 100 Loss 0.0524 Accuracy 0.4962\n",
      "Epoch 12 Loss 0.0523 Accuracy 0.4963\n",
      "Epoch 13 Batch 0 Loss 0.0227 Accuracy 0.4922\n",
      "Epoch 13 Batch 50 Loss 0.0483 Accuracy 0.4953\n",
      "Epoch 13 Batch 100 Loss 0.0492 Accuracy 0.4965\n",
      "Epoch 13 Loss 0.0502 Accuracy 0.4963\n",
      "Epoch 14 Batch 0 Loss 0.0835 Accuracy 0.4961\n",
      "Epoch 14 Batch 50 Loss 0.0566 Accuracy 0.4952\n",
      "Epoch 14 Batch 100 Loss 0.0577 Accuracy 0.4956\n",
      "Epoch 14 Loss 0.0567 Accuracy 0.4956\n",
      "Epoch 15 Batch 0 Loss 0.0203 Accuracy 0.5000\n",
      "Epoch 15 Batch 50 Loss 0.0445 Accuracy 0.4975\n",
      "Epoch 15 Batch 100 Loss 0.0506 Accuracy 0.4973\n",
      "Epoch 15 Loss 0.0497 Accuracy 0.4970\n",
      "Epoch 16 Batch 0 Loss 0.0079 Accuracy 0.5000\n",
      "Epoch 16 Batch 50 Loss 0.0507 Accuracy 0.4964\n",
      "Epoch 16 Batch 100 Loss 0.0503 Accuracy 0.4961\n",
      "Epoch 16 Loss 0.0512 Accuracy 0.4962\n",
      "Epoch 17 Batch 0 Loss 0.0387 Accuracy 0.5000\n",
      "Epoch 17 Batch 50 Loss 0.0397 Accuracy 0.4978\n",
      "Epoch 17 Batch 100 Loss 0.0467 Accuracy 0.4976\n",
      "Epoch 17 Loss 0.0455 Accuracy 0.4974\n",
      "Epoch 18 Batch 0 Loss 0.0183 Accuracy 0.5039\n",
      "Epoch 18 Batch 50 Loss 0.0471 Accuracy 0.4969\n",
      "Epoch 18 Batch 100 Loss 0.0481 Accuracy 0.4970\n",
      "Epoch 18 Loss 0.0506 Accuracy 0.4967\n",
      "Epoch 19 Batch 0 Loss 0.0371 Accuracy 0.4922\n",
      "Epoch 19 Batch 50 Loss 0.0491 Accuracy 0.4975\n",
      "Epoch 19 Batch 100 Loss 0.0509 Accuracy 0.4970\n",
      "Epoch 19 Loss 0.0513 Accuracy 0.4969\n",
      "Epoch 20 Batch 0 Loss 0.0243 Accuracy 0.4961\n",
      "Epoch 20 Batch 50 Loss 0.0476 Accuracy 0.4969\n",
      "Epoch 20 Batch 100 Loss 0.0505 Accuracy 0.4969\n",
      "Epoch 20 Loss 0.0517 Accuracy 0.4966\n",
      "Epoch 21 Batch 0 Loss 0.0307 Accuracy 0.5039\n",
      "Epoch 21 Batch 50 Loss 0.0448 Accuracy 0.4979\n",
      "Epoch 21 Batch 100 Loss 0.0451 Accuracy 0.4981\n",
      "Epoch 21 Loss 0.0471 Accuracy 0.4977\n",
      "Epoch 22 Batch 0 Loss 0.0311 Accuracy 0.5000\n",
      "Epoch 22 Batch 50 Loss 0.0439 Accuracy 0.4974\n",
      "Epoch 22 Batch 100 Loss 0.0453 Accuracy 0.4974\n",
      "Epoch 22 Loss 0.0464 Accuracy 0.4974\n",
      "Epoch 23 Batch 0 Loss 0.0416 Accuracy 0.4961\n",
      "Epoch 23 Batch 50 Loss 0.0567 Accuracy 0.4960\n",
      "Epoch 23 Batch 100 Loss 0.0516 Accuracy 0.4964\n",
      "Epoch 23 Loss 0.0502 Accuracy 0.4967\n",
      "Epoch 24 Batch 0 Loss 0.0411 Accuracy 0.4922\n",
      "Epoch 24 Batch 50 Loss 0.0608 Accuracy 0.4969\n",
      "Epoch 24 Batch 100 Loss 0.0576 Accuracy 0.4968\n",
      "Epoch 24 Loss 0.0550 Accuracy 0.4970\n",
      "Epoch 25 Batch 0 Loss 0.1516 Accuracy 0.4844\n",
      "Epoch 25 Batch 50 Loss 0.0437 Accuracy 0.4982\n",
      "Epoch 25 Batch 100 Loss 0.0460 Accuracy 0.4979\n",
      "Epoch 25 Loss 0.0483 Accuracy 0.4978\n",
      "Epoch 26 Batch 0 Loss 0.0398 Accuracy 0.4961\n",
      "Epoch 26 Batch 50 Loss 0.0563 Accuracy 0.4972\n",
      "Epoch 26 Batch 100 Loss 0.0515 Accuracy 0.4982\n",
      "Epoch 26 Loss 0.0526 Accuracy 0.4976\n",
      "Epoch 27 Batch 0 Loss 0.0203 Accuracy 0.4961\n",
      "Epoch 27 Batch 50 Loss 0.0514 Accuracy 0.4972\n",
      "Epoch 27 Batch 100 Loss 0.0478 Accuracy 0.4976\n",
      "Epoch 27 Loss 0.0465 Accuracy 0.4976\n",
      "Epoch 28 Batch 0 Loss 0.0422 Accuracy 0.4883\n",
      "Epoch 28 Batch 50 Loss 0.0518 Accuracy 0.4964\n",
      "Epoch 28 Batch 100 Loss 0.0506 Accuracy 0.4966\n",
      "Epoch 28 Loss 0.0625 Accuracy 0.4960\n",
      "Epoch 29 Batch 0 Loss 0.0371 Accuracy 0.5000\n",
      "Epoch 29 Batch 50 Loss 0.0676 Accuracy 0.4944\n",
      "Epoch 29 Batch 100 Loss 0.0588 Accuracy 0.4964\n",
      "Epoch 29 Loss 0.0602 Accuracy 0.4964\n",
      "Epoch 30 Batch 0 Loss 0.0097 Accuracy 0.5039\n",
      "Epoch 30 Batch 50 Loss 0.0559 Accuracy 0.4970\n",
      "Epoch 30 Batch 100 Loss 0.0498 Accuracy 0.4971\n",
      "Epoch 30 Loss 0.0505 Accuracy 0.4973\n",
      "Epoch 31 Batch 0 Loss 0.0093 Accuracy 0.5039\n",
      "Epoch 31 Batch 50 Loss 0.0495 Accuracy 0.4966\n",
      "Epoch 31 Batch 100 Loss 0.0534 Accuracy 0.4968\n",
      "Epoch 31 Loss 0.0543 Accuracy 0.4970\n",
      "Epoch 32 Batch 0 Loss 0.0613 Accuracy 0.5000\n",
      "Epoch 32 Batch 50 Loss 0.0843 Accuracy 0.4955\n",
      "Epoch 32 Batch 100 Loss 0.0732 Accuracy 0.4954\n",
      "Epoch 32 Loss 0.0693 Accuracy 0.4957\n",
      "Epoch 33 Batch 0 Loss 0.0961 Accuracy 0.5000\n",
      "Epoch 33 Batch 50 Loss 0.0658 Accuracy 0.4969\n",
      "Epoch 33 Batch 100 Loss 0.0590 Accuracy 0.4970\n",
      "Epoch 33 Loss 0.0558 Accuracy 0.4972\n",
      "Epoch 34 Batch 0 Loss 0.0147 Accuracy 0.5000\n",
      "Epoch 34 Batch 50 Loss 0.0439 Accuracy 0.4982\n",
      "Epoch 34 Batch 100 Loss 0.0449 Accuracy 0.4982\n",
      "Epoch 34 Loss 0.0480 Accuracy 0.4977\n",
      "Epoch 35 Batch 0 Loss 0.0101 Accuracy 0.5078\n",
      "Epoch 35 Batch 50 Loss 0.0606 Accuracy 0.4975\n",
      "Epoch 35 Batch 100 Loss 0.0591 Accuracy 0.4975\n",
      "Epoch 35 Loss 0.0551 Accuracy 0.4977\n",
      "Epoch 36 Batch 0 Loss 0.0370 Accuracy 0.5000\n",
      "Epoch 36 Batch 50 Loss 0.0595 Accuracy 0.4964\n",
      "Epoch 36 Batch 100 Loss 0.0616 Accuracy 0.4959\n",
      "Epoch 36 Loss 0.0709 Accuracy 0.4952\n",
      "Epoch 37 Batch 0 Loss 0.2974 Accuracy 0.4805\n",
      "Epoch 37 Batch 50 Loss 0.0927 Accuracy 0.4928\n",
      "Epoch 37 Batch 100 Loss 0.0954 Accuracy 0.4922\n",
      "Epoch 37 Loss 0.0933 Accuracy 0.4923\n",
      "Epoch 38 Batch 0 Loss 0.0486 Accuracy 0.4961\n",
      "Epoch 38 Batch 50 Loss 0.0791 Accuracy 0.4922\n",
      "Epoch 38 Batch 100 Loss 0.0740 Accuracy 0.4930\n",
      "Epoch 38 Loss 0.0747 Accuracy 0.4932\n",
      "Epoch 39 Batch 0 Loss 0.0919 Accuracy 0.4922\n",
      "Epoch 39 Batch 50 Loss 0.0633 Accuracy 0.4946\n",
      "Epoch 39 Batch 100 Loss 0.0715 Accuracy 0.4935\n",
      "Epoch 39 Loss 0.0719 Accuracy 0.4936\n",
      "Epoch 40 Batch 0 Loss 0.0630 Accuracy 0.5000\n",
      "Epoch 40 Batch 50 Loss 0.0682 Accuracy 0.4942\n",
      "Epoch 40 Batch 100 Loss 0.0653 Accuracy 0.4944\n",
      "Epoch 40 Loss 0.0638 Accuracy 0.4942\n",
      "Epoch 41 Batch 0 Loss 0.0314 Accuracy 0.4922\n",
      "Epoch 41 Batch 50 Loss 0.0601 Accuracy 0.4939\n",
      "Epoch 41 Batch 100 Loss 0.0626 Accuracy 0.4939\n",
      "Epoch 41 Loss 0.0650 Accuracy 0.4938\n",
      "Epoch 42 Batch 0 Loss 0.0629 Accuracy 0.4883\n",
      "Epoch 42 Batch 50 Loss 0.0619 Accuracy 0.4942\n",
      "Epoch 42 Batch 100 Loss 0.0713 Accuracy 0.4930\n",
      "Epoch 42 Loss 0.0716 Accuracy 0.4933\n",
      "Epoch 43 Batch 0 Loss 0.1354 Accuracy 0.4883\n",
      "Epoch 43 Batch 50 Loss 0.0841 Accuracy 0.4923\n",
      "Epoch 43 Batch 100 Loss 0.0715 Accuracy 0.4935\n",
      "Epoch 43 Loss 0.0669 Accuracy 0.4938\n",
      "Epoch 44 Batch 0 Loss 0.0206 Accuracy 0.5039\n",
      "Epoch 44 Batch 50 Loss 0.0502 Accuracy 0.4961\n",
      "Epoch 44 Batch 100 Loss 0.0509 Accuracy 0.4958\n",
      "Epoch 44 Loss 0.0542 Accuracy 0.4955\n",
      "Epoch 45 Batch 0 Loss 0.0107 Accuracy 0.5000\n",
      "Epoch 45 Batch 50 Loss 0.0517 Accuracy 0.4941\n",
      "Epoch 45 Batch 100 Loss 0.0506 Accuracy 0.4946\n",
      "Epoch 45 Loss 0.0533 Accuracy 0.4947\n",
      "Epoch 46 Batch 0 Loss 0.0553 Accuracy 0.5000\n",
      "Epoch 46 Batch 50 Loss 0.0554 Accuracy 0.4940\n",
      "Epoch 46 Batch 100 Loss 0.0520 Accuracy 0.4943\n",
      "Epoch 46 Loss 0.0522 Accuracy 0.4943\n",
      "Epoch 47 Batch 0 Loss 0.0612 Accuracy 0.4961\n",
      "Epoch 47 Batch 50 Loss 0.0583 Accuracy 0.4940\n",
      "Epoch 47 Batch 100 Loss 0.0489 Accuracy 0.4945\n",
      "Epoch 47 Loss 0.0487 Accuracy 0.4947\n",
      "Epoch 48 Batch 0 Loss 0.0274 Accuracy 0.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 50 Loss 0.0422 Accuracy 0.4959\n",
      "Epoch 48 Batch 100 Loss 0.0458 Accuracy 0.4955\n",
      "Epoch 48 Loss 0.0485 Accuracy 0.4954\n",
      "Epoch 49 Batch 0 Loss 0.1578 Accuracy 0.4922\n",
      "Epoch 49 Batch 50 Loss 0.0545 Accuracy 0.4948\n",
      "Epoch 49 Batch 100 Loss 0.0481 Accuracy 0.4953\n",
      "Epoch 49 Loss 0.0482 Accuracy 0.4954\n",
      "Epoch 50 Batch 0 Loss 0.0366 Accuracy 0.4922\n",
      "Epoch 50 Batch 50 Loss 0.0450 Accuracy 0.4945\n",
      "Epoch 50 Batch 100 Loss 0.0517 Accuracy 0.4952\n",
      "Epoch 50 Loss 0.0508 Accuracy 0.4952\n",
      "Epoch 51 Batch 0 Loss 0.0161 Accuracy 0.4961\n",
      "Epoch 51 Batch 50 Loss 0.0423 Accuracy 0.4962\n",
      "Epoch 51 Batch 100 Loss 0.0500 Accuracy 0.4954\n",
      "Epoch 51 Loss 0.0544 Accuracy 0.4952\n",
      "Epoch 52 Batch 0 Loss 0.0502 Accuracy 0.4922\n",
      "Epoch 52 Batch 50 Loss 0.0742 Accuracy 0.4941\n",
      "Epoch 52 Batch 100 Loss 0.0660 Accuracy 0.4939\n",
      "Epoch 52 Loss 0.0647 Accuracy 0.4939\n",
      "Epoch 53 Batch 0 Loss 0.0534 Accuracy 0.4961\n",
      "Epoch 53 Batch 50 Loss 0.0457 Accuracy 0.4958\n",
      "Epoch 53 Batch 100 Loss 0.0475 Accuracy 0.4954\n",
      "Epoch 53 Loss 0.0491 Accuracy 0.4953\n",
      "Epoch 54 Batch 0 Loss 0.0231 Accuracy 0.5000\n",
      "Epoch 54 Batch 50 Loss 0.0572 Accuracy 0.4954\n",
      "Epoch 54 Batch 100 Loss 0.0533 Accuracy 0.4952\n",
      "Epoch 54 Loss 0.0519 Accuracy 0.4953\n",
      "Epoch 55 Batch 0 Loss 0.0315 Accuracy 0.4961\n",
      "Epoch 55 Batch 50 Loss 0.0502 Accuracy 0.4975\n",
      "Epoch 55 Batch 100 Loss 0.0444 Accuracy 0.4975\n",
      "Epoch 55 Loss 0.0482 Accuracy 0.4974\n",
      "Epoch 56 Batch 0 Loss 0.0241 Accuracy 0.5000\n",
      "Epoch 56 Batch 50 Loss 0.0438 Accuracy 0.4980\n",
      "Epoch 56 Batch 100 Loss 0.0403 Accuracy 0.4981\n",
      "Epoch 56 Loss 0.0442 Accuracy 0.4977\n",
      "Epoch 57 Batch 0 Loss 0.0225 Accuracy 0.5000\n",
      "Epoch 57 Batch 50 Loss 0.0518 Accuracy 0.4955\n",
      "Epoch 57 Batch 100 Loss 0.0478 Accuracy 0.4957\n",
      "Epoch 57 Loss 0.0490 Accuracy 0.4954\n",
      "Epoch 58 Batch 0 Loss 0.0498 Accuracy 0.4961\n",
      "Epoch 58 Batch 50 Loss 0.0481 Accuracy 0.4952\n",
      "Epoch 58 Batch 100 Loss 0.0472 Accuracy 0.4952\n",
      "Epoch 58 Loss 0.0461 Accuracy 0.4951\n",
      "Epoch 59 Batch 0 Loss 0.0095 Accuracy 0.4961\n",
      "Epoch 59 Batch 50 Loss 0.0468 Accuracy 0.4957\n",
      "Epoch 59 Batch 100 Loss 0.0450 Accuracy 0.4955\n",
      "Epoch 59 Loss 0.0460 Accuracy 0.4955\n",
      "Epoch 60 Batch 0 Loss 0.0389 Accuracy 0.4961\n",
      "Epoch 60 Batch 50 Loss 0.0401 Accuracy 0.4959\n",
      "Epoch 60 Batch 100 Loss 0.0441 Accuracy 0.4954\n",
      "Epoch 60 Loss 0.0452 Accuracy 0.4951\n",
      "Epoch 61 Batch 0 Loss 0.0776 Accuracy 0.5000\n",
      "Epoch 61 Batch 50 Loss 0.0427 Accuracy 0.4958\n",
      "Epoch 61 Batch 100 Loss 0.0434 Accuracy 0.4959\n",
      "Epoch 61 Loss 0.0439 Accuracy 0.4957\n",
      "Epoch 62 Batch 0 Loss 0.0263 Accuracy 0.4961\n",
      "Epoch 62 Batch 50 Loss 0.0411 Accuracy 0.4958\n",
      "Epoch 62 Batch 100 Loss 0.0431 Accuracy 0.4957\n",
      "Epoch 62 Loss 0.0446 Accuracy 0.4958\n",
      "Epoch 63 Batch 0 Loss 0.0058 Accuracy 0.5000\n",
      "Epoch 63 Batch 50 Loss 0.0481 Accuracy 0.4957\n",
      "Epoch 63 Batch 100 Loss 0.0450 Accuracy 0.4956\n",
      "Epoch 63 Loss 0.0435 Accuracy 0.4956\n",
      "Epoch 64 Batch 0 Loss 0.0489 Accuracy 0.5000\n",
      "Epoch 64 Batch 50 Loss 0.0396 Accuracy 0.4964\n",
      "Epoch 64 Batch 100 Loss 0.0447 Accuracy 0.4959\n",
      "Epoch 64 Loss 0.0476 Accuracy 0.4960\n",
      "Epoch 65 Batch 0 Loss 0.0770 Accuracy 0.4883\n",
      "Epoch 65 Batch 50 Loss 0.0459 Accuracy 0.4956\n",
      "Epoch 65 Batch 100 Loss 0.0472 Accuracy 0.4956\n",
      "Epoch 65 Loss 0.0470 Accuracy 0.4956\n",
      "Epoch 66 Batch 0 Loss 0.0488 Accuracy 0.4961\n",
      "Epoch 66 Batch 50 Loss 0.0482 Accuracy 0.4956\n",
      "Epoch 66 Batch 100 Loss 0.0466 Accuracy 0.4961\n",
      "Epoch 66 Loss 0.0453 Accuracy 0.4957\n",
      "Epoch 67 Batch 0 Loss 0.0242 Accuracy 0.5000\n",
      "Epoch 67 Batch 50 Loss 0.0464 Accuracy 0.4965\n",
      "Epoch 67 Batch 100 Loss 0.0480 Accuracy 0.4958\n",
      "Epoch 67 Loss 0.0477 Accuracy 0.4957\n",
      "Epoch 68 Batch 0 Loss 0.0228 Accuracy 0.4961\n",
      "Epoch 68 Batch 50 Loss 0.0523 Accuracy 0.4956\n",
      "Epoch 68 Batch 100 Loss 0.0541 Accuracy 0.4949\n",
      "Epoch 68 Loss 0.0552 Accuracy 0.4945\n",
      "Epoch 69 Batch 0 Loss 0.0542 Accuracy 0.4961\n",
      "Epoch 69 Batch 50 Loss 0.0798 Accuracy 0.4890\n",
      "Epoch 69 Batch 100 Loss 0.0987 Accuracy 0.4866\n",
      "Epoch 69 Loss 0.0902 Accuracy 0.4880\n",
      "Epoch 70 Batch 0 Loss 0.0733 Accuracy 0.4922\n",
      "Epoch 70 Batch 50 Loss 0.0652 Accuracy 0.4913\n",
      "Epoch 70 Batch 100 Loss 0.0615 Accuracy 0.4921\n",
      "Epoch 70 Loss 0.0617 Accuracy 0.4921\n",
      "Epoch 71 Batch 0 Loss 0.0103 Accuracy 0.4961\n",
      "Epoch 71 Batch 50 Loss 0.0612 Accuracy 0.4919\n",
      "Epoch 71 Batch 100 Loss 0.0609 Accuracy 0.4925\n",
      "Epoch 71 Loss 0.0645 Accuracy 0.4922\n",
      "Epoch 72 Batch 0 Loss 0.0394 Accuracy 0.4961\n",
      "Epoch 72 Batch 50 Loss 0.0633 Accuracy 0.4906\n",
      "Epoch 72 Batch 100 Loss 0.0610 Accuracy 0.4910\n",
      "Epoch 72 Loss 0.0601 Accuracy 0.4914\n",
      "Epoch 73 Batch 0 Loss 0.0160 Accuracy 0.5000\n",
      "Epoch 73 Batch 50 Loss 0.0588 Accuracy 0.4914\n",
      "Epoch 73 Batch 100 Loss 0.3264 Accuracy 0.4230\n",
      "Epoch 73 Loss 0.3632 Accuracy 0.4151\n",
      "Epoch 74 Batch 0 Loss 0.4268 Accuracy 0.4219\n",
      "Epoch 74 Batch 50 Loss 0.4310 Accuracy 0.4153\n",
      "Epoch 74 Batch 100 Loss 0.4109 Accuracy 0.4209\n",
      "Epoch 74 Loss 0.3946 Accuracy 0.4231\n",
      "Epoch 75 Batch 0 Loss 0.2545 Accuracy 0.4414\n",
      "Epoch 75 Batch 50 Loss 0.2078 Accuracy 0.4580\n",
      "Epoch 75 Batch 100 Loss 0.1695 Accuracy 0.4683\n",
      "Epoch 75 Loss 0.1599 Accuracy 0.4713\n",
      "Epoch 76 Batch 0 Loss 0.1500 Accuracy 0.4844\n",
      "Epoch 76 Batch 50 Loss 0.1096 Accuracy 0.4851\n",
      "Epoch 76 Batch 100 Loss 0.1007 Accuracy 0.4871\n",
      "Epoch 76 Loss 0.1005 Accuracy 0.4866\n",
      "Epoch 77 Batch 0 Loss 0.0444 Accuracy 0.4922\n",
      "Epoch 77 Batch 50 Loss 0.0848 Accuracy 0.4900\n",
      "Epoch 77 Batch 100 Loss 0.0802 Accuracy 0.4905\n",
      "Epoch 77 Loss 0.0791 Accuracy 0.4906\n",
      "Epoch 78 Batch 0 Loss 0.0908 Accuracy 0.4961\n",
      "Epoch 78 Batch 50 Loss 0.0799 Accuracy 0.4916\n",
      "Epoch 78 Batch 100 Loss 0.0740 Accuracy 0.4912\n",
      "Epoch 78 Loss 0.0745 Accuracy 0.4909\n",
      "Epoch 79 Batch 0 Loss 0.0492 Accuracy 0.4883\n",
      "Epoch 79 Batch 50 Loss 0.0727 Accuracy 0.4927\n",
      "Epoch 79 Batch 100 Loss 0.0631 Accuracy 0.4933\n",
      "Epoch 79 Loss 0.0642 Accuracy 0.4931\n",
      "Epoch 80 Batch 0 Loss 0.0306 Accuracy 0.5000\n",
      "Epoch 80 Batch 50 Loss 0.0601 Accuracy 0.4937\n",
      "Epoch 80 Batch 100 Loss 0.0563 Accuracy 0.4940\n",
      "Epoch 80 Loss 0.0580 Accuracy 0.4941\n",
      "Epoch 81 Batch 0 Loss 0.1440 Accuracy 0.4805\n",
      "Epoch 81 Batch 50 Loss 0.0469 Accuracy 0.4943\n",
      "Epoch 81 Batch 100 Loss 0.0495 Accuracy 0.4949\n",
      "Epoch 81 Loss 0.0497 Accuracy 0.4949\n",
      "Epoch 82 Batch 0 Loss 0.0315 Accuracy 0.4961\n",
      "Epoch 82 Batch 50 Loss 0.0466 Accuracy 0.4959\n",
      "Epoch 82 Batch 100 Loss 0.0460 Accuracy 0.4956\n",
      "Epoch 82 Loss 0.0496 Accuracy 0.4951\n",
      "Epoch 83 Batch 0 Loss 0.0188 Accuracy 0.5039\n",
      "Epoch 83 Batch 50 Loss 0.0489 Accuracy 0.4963\n",
      "Epoch 83 Batch 100 Loss 0.0491 Accuracy 0.4962\n",
      "Epoch 83 Loss 0.0513 Accuracy 0.4963\n",
      "Epoch 84 Batch 0 Loss 0.1408 Accuracy 0.4844\n",
      "Epoch 84 Batch 50 Loss 0.0728 Accuracy 0.4932\n",
      "Epoch 84 Batch 100 Loss 0.0641 Accuracy 0.4941\n",
      "Epoch 84 Loss 0.0602 Accuracy 0.4946\n",
      "Epoch 85 Batch 0 Loss 0.0213 Accuracy 0.5000\n",
      "Epoch 85 Batch 50 Loss 0.0478 Accuracy 0.4950\n",
      "Epoch 85 Batch 100 Loss 0.0505 Accuracy 0.4952\n",
      "Epoch 85 Loss 0.0484 Accuracy 0.4955\n",
      "Epoch 86 Batch 0 Loss 0.0561 Accuracy 0.5039\n",
      "Epoch 86 Batch 50 Loss 0.0502 Accuracy 0.4964\n",
      "Epoch 86 Batch 100 Loss 0.0501 Accuracy 0.4955\n",
      "Epoch 86 Loss 0.0519 Accuracy 0.4953\n",
      "Epoch 87 Batch 0 Loss 0.0141 Accuracy 0.5000\n",
      "Epoch 87 Batch 50 Loss 0.0468 Accuracy 0.4972\n",
      "Epoch 87 Batch 100 Loss 0.0483 Accuracy 0.4964\n",
      "Epoch 87 Loss 0.0624 Accuracy 0.4953\n",
      "Epoch 88 Batch 0 Loss 0.0075 Accuracy 0.5000\n",
      "Epoch 88 Batch 50 Loss 0.0462 Accuracy 0.4970\n",
      "Epoch 88 Batch 100 Loss 0.0476 Accuracy 0.4966\n",
      "Epoch 88 Loss 0.0501 Accuracy 0.4962\n",
      "Epoch 89 Batch 0 Loss 0.0545 Accuracy 0.5039\n",
      "Epoch 89 Batch 50 Loss 0.0428 Accuracy 0.4961\n",
      "Epoch 89 Batch 100 Loss 0.0435 Accuracy 0.4959\n",
      "Epoch 89 Loss 0.0418 Accuracy 0.4959\n",
      "Epoch 90 Batch 0 Loss 0.0207 Accuracy 0.5000\n",
      "Epoch 90 Batch 50 Loss 0.0405 Accuracy 0.4955\n",
      "Epoch 90 Batch 100 Loss 0.0428 Accuracy 0.4960\n",
      "Epoch 90 Loss 0.0426 Accuracy 0.4960\n",
      "Epoch 91 Batch 0 Loss 0.0119 Accuracy 0.5000\n",
      "Epoch 91 Batch 50 Loss 0.0528 Accuracy 0.4950\n",
      "Epoch 91 Batch 100 Loss 0.0486 Accuracy 0.4948\n",
      "Epoch 91 Loss 0.0456 Accuracy 0.4953\n",
      "Epoch 92 Batch 0 Loss 0.0409 Accuracy 0.4961\n",
      "Epoch 92 Batch 50 Loss 0.0422 Accuracy 0.4958\n",
      "Epoch 92 Batch 100 Loss 0.0394 Accuracy 0.4959\n",
      "Epoch 92 Loss 0.0404 Accuracy 0.4957\n",
      "Epoch 93 Batch 0 Loss 0.0482 Accuracy 0.4961\n",
      "Epoch 93 Batch 50 Loss 0.0422 Accuracy 0.4956\n",
      "Epoch 93 Batch 100 Loss 0.0404 Accuracy 0.4956\n",
      "Epoch 93 Loss 0.0411 Accuracy 0.4956\n",
      "Epoch 94 Batch 0 Loss 0.0291 Accuracy 0.4961\n",
      "Epoch 94 Batch 50 Loss 0.0452 Accuracy 0.4963\n",
      "Epoch 94 Batch 100 Loss 0.0434 Accuracy 0.4965\n",
      "Epoch 94 Loss 0.0461 Accuracy 0.4962\n",
      "Epoch 95 Batch 0 Loss 0.0828 Accuracy 0.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 50 Loss 0.0501 Accuracy 0.4968\n",
      "Epoch 95 Batch 100 Loss 0.0620 Accuracy 0.4940\n",
      "Epoch 95 Loss 0.0589 Accuracy 0.4938\n",
      "Epoch 96 Batch 0 Loss 0.0497 Accuracy 0.5000\n",
      "Epoch 96 Batch 50 Loss 0.0623 Accuracy 0.4941\n",
      "Epoch 96 Batch 100 Loss 0.0556 Accuracy 0.4940\n",
      "Epoch 96 Loss 0.0552 Accuracy 0.4940\n",
      "Epoch 97 Batch 0 Loss 0.0055 Accuracy 0.5000\n",
      "Epoch 97 Batch 50 Loss 0.0549 Accuracy 0.4944\n",
      "Epoch 97 Batch 100 Loss 0.0527 Accuracy 0.4942\n",
      "Epoch 97 Loss 0.0523 Accuracy 0.4942\n",
      "Epoch 98 Batch 0 Loss 0.0172 Accuracy 0.4961\n",
      "Epoch 98 Batch 50 Loss 0.0430 Accuracy 0.4963\n",
      "Epoch 98 Batch 100 Loss 0.0492 Accuracy 0.4956\n",
      "Epoch 98 Loss 0.0495 Accuracy 0.4952\n",
      "Epoch 99 Batch 0 Loss 0.0202 Accuracy 0.4961\n",
      "Epoch 99 Batch 50 Loss 0.0492 Accuracy 0.4959\n",
      "Epoch 99 Batch 100 Loss 0.0482 Accuracy 0.4962\n",
      "Epoch 99 Loss 0.0484 Accuracy 0.4961\n",
      "Epoch 100 Batch 0 Loss 0.0348 Accuracy 0.5000\n",
      "Epoch 100 Batch 50 Loss 0.0508 Accuracy 0.4953\n",
      "Epoch 100 Batch 100 Loss 0.0508 Accuracy 0.4963\n",
      "Epoch 100 Loss 0.0507 Accuracy 0.4960\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', '!']\n"
     ]
    }
   ],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: what is going on?\n",
      "Predicted translation: ['<start>', '?']\n"
     ]
    }
   ],
   "source": [
    "translate(\"what is going on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
