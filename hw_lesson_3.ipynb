{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns3Tk3oHkSRR"
   },
   "source": [
    "HW 3 Мельчук А.Б."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TM7kV3k6kSRS"
   },
   "source": [
    "Тема “Создание признакового пространства”\n",
    "\n",
    "Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'.\n",
    "\n",
    "## Задание 1.\n",
    "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)\n",
    "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
    "Повторим шаги из заданий 1 и 2, используя библиотеку nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zmo6Ys26kSRT"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sa7tp7nek7qW",
    "outputId": "d9518008-195b-4a5c-bbc4-ebd2616592a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5DYKQ0bkSRW"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "NWSAn6m4kSRZ",
    "outputId": "349a5905-8511-4f00-9bf5-f6b538a3c361"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ...                                   tweet_lemmatized\n",
       "0   1  ...  [father, dysfunctional, selfish, drag, kid, dy...\n",
       "1   2  ...  [thanks, lyft, credit, use, cause, offer, whee...\n",
       "2   3  ...                                  [bihday, majesty]\n",
       "3   4  ...                      [model, love, take, time, ur]\n",
       "4   5  ...                  [factsguide, society, motivation]\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_pickle('/content/drive/My Drive/gu-nlp/combine_df.pkl')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "cMNvDqxjkSRc",
    "outputId": "91e76739-00fd-49db-b6b4-fac6ac691449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_md==2.3.1\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz (50.8MB)\n",
      "\u001b[K     |████████████████████████████████| 50.8MB 74.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (49.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.23.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.41.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.7.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.1.0)\n",
      "Building wheels for collected packages: en-core-web-md\n",
      "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-md: filename=en_core_web_md-2.3.1-cp36-none-any.whl size=50916643 sha256=271b991e4df9557a89a8b0a58b08958546eff73dd37f8fdf8ac857bf98a32d3b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mbmtak15/wheels/6e/65/3a/34cdc26d4084d1d1f1e2ec9914964759ea17aa382c53a57d9f\n",
      "Successfully built en-core-web-md\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-2.3.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U spacy\n",
    "#!python -m spacy info\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0e6Q3KkkSRi"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()\n",
    "\n",
    "ner_sp = {\n",
    "    \"text\": [],\n",
    "    \"label\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tzf1pjFv29M"
   },
   "outputs": [],
   "source": [
    "def build_ner_sp(t):\n",
    "    for ent in nlp(t).ents:\n",
    "        ner_sp['text'].append(ent.text)\n",
    "        ner_sp['label'].append(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "1RqUyyjokSRn",
    "outputId": "382fffe4-8c27-4043-bd7c-e7e07d4a3397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "49154    None\n",
       "49155    None\n",
       "49156    None\n",
       "49157    None\n",
       "49158    None\n",
       "Name: tweet, Length: 49159, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweet'].apply(lambda x: build_ner_sp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "edJyJr9zkSRq",
    "outputId": "90ae77c9-fefd-43a1-d785-846611439642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pdx</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>getthanked</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>danny</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text   label\n",
       "0         pdx     GPE\n",
       "1  getthanked  PERSON\n",
       "2      bihday    DATE\n",
       "3    tomorrow    DATE\n",
       "4       danny  PERSON"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_sp = pd.DataFrame.from_dict(ner_sp)\n",
    "ner_df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "8SRvnmsFkSRs",
    "outputId": "be84191d-1ebe-40b8-fff6-c1b2124b3b28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "today       1397\n",
       "tomorrow     597\n",
       "friday       588\n",
       "one          518\n",
       "first        514\n",
       "orlando      473\n",
       "sunday       466\n",
       "morning      432\n",
       "tonight      420\n",
       "bihday       406\n",
       "summer       402\n",
       "saturday     323\n",
       "monday       242\n",
       "america      218\n",
       "night        198\n",
       "two          183\n",
       "days         179\n",
       "weekend      172\n",
       "london       169\n",
       "thursday     165\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_sp.text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "H0gqfweukSRu",
    "outputId": "c3da4a74-db47-48d1-97e2-22ff61713096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bing bong bing bong                                        107\n",
       "suppo                                                       69\n",
       "obama                                                       67\n",
       "hillary                                                     55\n",
       "sta                                                         45\n",
       "melancholy melancholymusic                                  40\n",
       "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
       "bjp                                                         36\n",
       "christina grimmie                                           34\n",
       "hu                                                          30\n",
       "jo cox                                                      29\n",
       "tgif ff                                                     26\n",
       "lebron                                                      26\n",
       "gamedev indiedev indiegamedev                               25\n",
       "donald trump                                                25\n",
       "sea shepherd suppoers                                       25\n",
       "clinton                                                     22\n",
       "boricua                                                     22\n",
       "th bihday                                                   22\n",
       "jesus                                                       22\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_sp.loc[ner_df_sp['label'] == 'PERSON'].text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "KsDXNUagkSRw",
    "outputId": "8a8008b5-42b4-4fde-f6b4-d8fec01699a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sjw                 102\n",
       "allahsoil            84\n",
       "gop                  76\n",
       "nba                  59\n",
       "islam                53\n",
       "trump                50\n",
       "ht                   42\n",
       "facebook             40\n",
       "bihday               39\n",
       "cavs                 39\n",
       "social analytics     34\n",
       "ios                  30\n",
       "obama                30\n",
       "cnn                  30\n",
       "google               29\n",
       "wso                  28\n",
       "eu                   26\n",
       "congress             22\n",
       "kkk                  20\n",
       "spo                  20\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_sp.loc[ner_df_sp['label'] == 'ORG'].text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FD0g1nUpqxw-"
   },
   "source": [
    "## Задание 2.\n",
    "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
    "\n",
    "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOCyFdBikSRy"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5K8y8frGpScP",
    "outputId": "0de0eec3-dc42-4f9e-ba1b-c32ec1c1a7fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2glSqZvIkSR0"
   },
   "outputs": [],
   "source": [
    "ner_nltk = {\n",
    "    \"text\": [],\n",
    "    \"label\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YunrGD0vkSR2"
   },
   "outputs": [],
   "source": [
    "def build_nltk_ner(tweet):\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(tweet.title()))):\n",
    "         if hasattr(chunk, 'label'):\n",
    "            ner_nltk['text'].append(' '.join(c[0] for c in chunk))\n",
    "            ner_nltk['label'].append(chunk.label())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "WTXGQwiykSR4",
    "outputId": "6d7d605b-b7d5-423e-edb3-c523d97a67f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "49154    None\n",
       "49155    None\n",
       "49156    None\n",
       "49157    None\n",
       "49158    None\n",
       "Name: tweet, Length: 49159, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweet'].apply(lambda x: build_nltk_ner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "d3GyLCJPkSR7",
    "outputId": "f1cf9040-387b-46d3-bbc5-331b41bd506d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Father</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kids</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lyft Credit</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offer Wheelchair</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pdx</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text         label\n",
       "0            Father        PERSON\n",
       "1              Kids  ORGANIZATION\n",
       "2       Lyft Credit        PERSON\n",
       "3  Offer Wheelchair        PERSON\n",
       "4               Pdx           GPE"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk = pd.DataFrame.from_dict(ner_nltk)\n",
    "ner_df_ntlk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "Xw8pYAvBkSR9",
    "outputId": "5aea2e86-9842-40e4-8e36-f1e228d82153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happy                1113\n",
       "New                   528\n",
       "Model                 500\n",
       "Ur                    498\n",
       "Father                498\n",
       "Good                  422\n",
       "Love                  365\n",
       "Will                  347\n",
       "Great                 271\n",
       "Us                    264\n",
       "Bull Up               246\n",
       "Orlando               239\n",
       "Life                  204\n",
       "Sad                   191\n",
       "Ready                 191\n",
       "Forward               168\n",
       "Have                  165\n",
       "Gorilla Simulator     162\n",
       "Trump                 147\n",
       "Got                   147\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk.text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "vi8sdfFKkSR_",
    "outputId": "57b00b82-6c9f-4315-a8c2-d183e7122a8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Well Deletetweets                         126\n",
       "Development Organizations Work Mindset     95\n",
       "Vicinity Of Their                          89\n",
       "Fathers                                    79\n",
       "Vast Expanse Of Mountains                  76\n",
       "Lot                                        68\n",
       "House                                      67\n",
       "Work Conference                            65\n",
       "Happiness                                  61\n",
       "City Each Side                             54\n",
       "Same                                       53\n",
       "All                                        53\n",
       "Melancholy Melancholymusic                 46\n",
       "Love                                       43\n",
       "Hate                                       37\n",
       "Weekend                                    37\n",
       "Into                                       37\n",
       "No                                         36\n",
       "Best                                       36\n",
       "Get Get Enjoy Music                        34\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk.loc[ner_df_ntlk['label'] == 'ORGANIZATION'].text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "Teh1oNZ0kSSB",
    "outputId": "6e75fd22-55fd-4183-a09a-4319dbf243e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happy                       995\n",
       "Model                       498\n",
       "Father                      485\n",
       "Will                        345\n",
       "Good                        313\n",
       "Love                        253\n",
       "Bull Up                     246\n",
       "Sad                         169\n",
       "Forward                     166\n",
       "Gorilla Simulator           162\n",
       "Have                        159\n",
       "Delete Old                  130\n",
       "Found Way How               130\n",
       "Ready                       127\n",
       "Trump                       118\n",
       "Aww                         115\n",
       "Attack Bull                 115\n",
       "Help                        112\n",
       "Good Bing Bong Bing Bong    107\n",
       "Hey                         107\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk.loc[ner_df_ntlk['label'] == 'PERSON'].text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HgPPRpzq2qW"
   },
   "source": [
    "## Задание 3.\n",
    "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5wDVjzjkSSD"
   },
   "source": [
    "Библиотека spacy работает сильно лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0kEn5E-kSSD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw_lesson_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
